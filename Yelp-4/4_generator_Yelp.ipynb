{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre_dict = pickle.load(open('./item_genre_dict.pkl'))\n",
    "rdf = pickle.load(open('./rdf.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 31025\n",
      "user num = 102612\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Restaurants', 31025),\n",
       " (u'Food', 5598),\n",
       " (u'Nightlife', 5111),\n",
       " (u'Bars', 4958),\n",
       " (u'American (Traditional)', 4340),\n",
       " (u'Sandwiches', 3574),\n",
       " (u'Pizza', 3131),\n",
       " (u'Breakfast & Brunch', 3127),\n",
       " (u'American (New)', 3022),\n",
       " (u'Fast Food', 2992),\n",
       " (u'Mexican', 2854),\n",
       " (u'Italian', 2761),\n",
       " (u'Burgers', 2732),\n",
       " (u'Chinese', 2467),\n",
       " (u'Japanese', 1703),\n",
       " (u'Seafood', 1606),\n",
       " (u'Salad', 1470),\n",
       " (u'Cafes', 1447),\n",
       " (u'Sushi Bars', 1430),\n",
       " (u'Asian Fusion', 1217),\n",
       " (u'Chicken Wings', 1189),\n",
       " (u'Coffee & Tea', 1173),\n",
       " (u'Sports Bars', 1093),\n",
       " (u'Event Planning & Services', 1093),\n",
       " (u'Steakhouses', 1072),\n",
       " (u'Mediterranean', 1007),\n",
       " (u'Barbeque', 995),\n",
       " (u'Delis', 940),\n",
       " (u'Canadian (New)', 904),\n",
       " (u'Pubs', 891),\n",
       " (u'Diners', 883),\n",
       " (u'Thai', 881),\n",
       " (u'Caterers', 807),\n",
       " (u'Desserts', 786),\n",
       " (u'Indian', 779),\n",
       " (u'Specialty Food', 756),\n",
       " (u'Vegetarian', 730),\n",
       " (u'Bakeries', 673),\n",
       " (u'Wine Bars', 644),\n",
       " (u'Vietnamese', 617),\n",
       " (u'Middle Eastern', 600),\n",
       " (u'Greek', 590),\n",
       " (u'Cocktail Bars', 574),\n",
       " (u'Buffets', 570),\n",
       " (u'French', 561),\n",
       " (u'Wine & Spirits', 554),\n",
       " (u'Beer', 554),\n",
       " (u'Soup', 518),\n",
       " (u'Korean', 515),\n",
       " (u'Gluten-Free', 494),\n",
       " (u'Vegan', 482),\n",
       " (u'Tex-Mex', 458),\n",
       " (u'Lounges', 435),\n",
       " (u'Comfort Food', 429),\n",
       " (u'Arts & Entertainment', 409),\n",
       " (u'Juice Bars & Smoothies', 384),\n",
       " (u'Gastropubs', 376),\n",
       " (u'Hot Dogs', 360),\n",
       " (u'Ice Cream & Frozen Yogurt', 335),\n",
       " (u'Ethnic Food', 334),\n",
       " (u'Latin American', 332),\n",
       " (u'Southern', 313),\n",
       " (u'Tapas/Small Plates', 294),\n",
       " (u'Food Delivery Services', 278),\n",
       " (u'Caribbean', 272),\n",
       " (u'Noodles', 262),\n",
       " (u'Halal', 246),\n",
       " (u'Bagels', 245),\n",
       " (u'Venues & Event Spaces', 219),\n",
       " (u'Tapas Bars', 218),\n",
       " (u'Hawaiian', 213),\n",
       " (u'Music Venues', 201),\n",
       " (u'Pakistani', 199),\n",
       " (u'Dim Sum', 192),\n",
       " (u'British', 188),\n",
       " (u'Food Trucks', 181),\n",
       " (u'Grocery', 180),\n",
       " (u'Cajun/Creole', 169),\n",
       " (u'Beer Bar', 165),\n",
       " (u'Fish & Chips', 162),\n",
       " (u'Breweries', 162),\n",
       " (u'German', 147),\n",
       " (u'Modern European', 147),\n",
       " (u'Ramen', 146),\n",
       " (u'Chicken Shop', 144),\n",
       " (u'Soul Food', 144),\n",
       " (u'Creperies', 138),\n",
       " (u'Irish', 136),\n",
       " (u'Cheesesteaks', 132),\n",
       " (u'Dive Bars', 130),\n",
       " (u'Spanish', 127),\n",
       " (u'Taiwanese', 125),\n",
       " (u'Portuguese', 121),\n",
       " (u'Imported Food', 119),\n",
       " (u'Filipino', 110),\n",
       " (u'Food Stands', 108),\n",
       " (u'Tacos', 104),\n",
       " (u'Hotels & Travel', 102),\n",
       " (u'Karaoke', 99),\n",
       " (u'Brasseries', 99),\n",
       " (u'Shopping', 98),\n",
       " (u'Persian/Iranian', 97),\n",
       " (u'Street Vendors', 95),\n",
       " (u'Turkish', 92),\n",
       " (u'Lebanese', 89),\n",
       " (u'Tea Rooms', 85),\n",
       " (u'Dance Clubs', 82),\n",
       " (u'Local Flavor', 80),\n",
       " (u'Poke', 79),\n",
       " (u'Bubble Tea', 77),\n",
       " (u'Poutineries', 74),\n",
       " (u'Active Life', 72),\n",
       " (u'African', 71),\n",
       " (u'Falafel', 67),\n",
       " (u'Szechuan', 64),\n",
       " (u'Hot Pot', 63),\n",
       " (u'Bistros', 61),\n",
       " (u'Wraps', 61),\n",
       " (u'Waffles', 61),\n",
       " (u'Cantonese', 58),\n",
       " (u'Party & Event Planning', 58),\n",
       " (u'Peruvian', 58),\n",
       " (u'Donuts', 55),\n",
       " (u'Brazilian', 55),\n",
       " (u'Health Markets', 53),\n",
       " (u'Afghan', 52),\n",
       " (u'Food Court', 51),\n",
       " (u'Hotels', 51),\n",
       " (u'Malaysian', 50),\n",
       " (u'Meat Shops', 50),\n",
       " (u'Cuban', 49),\n",
       " (u'Ethiopian', 49),\n",
       " (u'Casinos', 49),\n",
       " (u'Polish', 48),\n",
       " (u'Irish Pub', 47),\n",
       " (u'Hookah Bars', 45),\n",
       " (u'Live/Raw Food', 45),\n",
       " (u'Pan Asian', 43),\n",
       " (u'Jazz & Blues', 42),\n",
       " (u'Arcades', 41),\n",
       " (u'Kosher', 40),\n",
       " (u'Himalayan/Nepalese', 39),\n",
       " (u'Mongolian', 38),\n",
       " (u'Bed & Breakfast', 37),\n",
       " (u'Seafood Markets', 36),\n",
       " (u'Scottish', 36),\n",
       " (u'Internet Cafes', 36),\n",
       " (u'Do-It-Yourself Food', 36),\n",
       " (u'Beer Gardens', 35),\n",
       " (u'Salvadoran', 35),\n",
       " (u'International', 35),\n",
       " (u'Fondue', 34),\n",
       " (u'Belgian', 34),\n",
       " (u'Pasta Shops', 34),\n",
       " (u'Convenience Stores', 33),\n",
       " (u'Swabian', 33),\n",
       " (u'Pool Halls', 32),\n",
       " (u'Moroccan', 31),\n",
       " (u'Smokehouse', 31),\n",
       " (u'Butcher', 30),\n",
       " (u'Beer Garden', 28),\n",
       " (u'Arabian', 28),\n",
       " (u'Colombian', 28),\n",
       " (u'Organic Stores', 27),\n",
       " (u'Delicatessen', 27),\n",
       " (u'Gelato', 27),\n",
       " (u'Cheese Shops', 25),\n",
       " (u'Russian', 24),\n",
       " (u'Patisserie/Cake Shop', 24),\n",
       " (u'New Mexican Cuisine', 24),\n",
       " (u'Shaved Ice', 23),\n",
       " (u'Wineries', 23),\n",
       " (u'Chocolatiers & Shops', 23),\n",
       " (u'Fruits & Veggies', 22),\n",
       " (u'Whiskey Bars', 22),\n",
       " (u'Local Services', 21),\n",
       " (u'Kebab', 21),\n",
       " (u'Acai Bowls', 21),\n",
       " (u'Cambodian', 21),\n",
       " (u'Basque', 20),\n",
       " (u'Teppanyaki', 19),\n",
       " (u'Bowling', 19),\n",
       " (u'Argentine', 19),\n",
       " (u'Golf', 19),\n",
       " (u'Hungarian', 18),\n",
       " (u'Coffee Roasteries', 18),\n",
       " (u'Venezuelan', 17),\n",
       " (u'Singaporean', 17),\n",
       " (u'Farmers Market', 15),\n",
       " (u'Hakka', 15),\n",
       " (u'Puerto Rican', 15),\n",
       " (u'Cupcakes', 14),\n",
       " (u'International Grocery', 13),\n",
       " (u'Indonesian', 13),\n",
       " (u'Automotive', 12),\n",
       " (u'Health & Medical', 12),\n",
       " (u'Donairs', 12),\n",
       " (u'Performing Arts', 12),\n",
       " (u'Ukrainian', 12),\n",
       " (u'Education', 12),\n",
       " (u'Wigs', 12),\n",
       " (u'Sri Lankan', 12),\n",
       " (u'Scandinavian', 11),\n",
       " (u'Laotian', 11),\n",
       " (u'Home Services', 11),\n",
       " (u'Beauty & Spas', 11),\n",
       " (u'Gay Bars', 11),\n",
       " (u'Flowers & Gifts', 11),\n",
       " (u'Custom Cakes', 11),\n",
       " (u'Pretzels', 10),\n",
       " (u'South African', 10),\n",
       " (u'Izakaya', 10),\n",
       " (u'Wedding Planning', 10),\n",
       " (u'Art Galleries', 9),\n",
       " (u'Eatertainment', 9),\n",
       " (u'Festivals', 9),\n",
       " (u'Cafeteria', 9),\n",
       " (u'Mags', 9),\n",
       " (u'Music & Video', 9),\n",
       " (u'Books', 9),\n",
       " (u'Country Dance Halls', 8),\n",
       " (u'Shanghainese', 8),\n",
       " (u'Speakeasies', 8),\n",
       " (u'Burmese', 8),\n",
       " (u'Bangladeshi', 8),\n",
       " (u'Social Clubs', 8),\n",
       " (u'Egyptian', 8),\n",
       " (u'Fashion', 8),\n",
       " (u'Home & Garden', 8),\n",
       " (u'Gas Stations', 8),\n",
       " (u'Macarons', 7),\n",
       " (u'Tobacco Shops', 7),\n",
       " (u'Brewpubs', 7),\n",
       " (u'Dinner Theater', 7),\n",
       " (u'Dominican', 7),\n",
       " (u'Bavarian', 7),\n",
       " (u'Piano Bars', 7),\n",
       " (u'Specialty Schools', 7),\n",
       " (u'Cinema', 7),\n",
       " (u'Resorts', 7),\n",
       " (u'Cooking Schools', 7),\n",
       " (u'Empanadas', 6),\n",
       " (u'Armenian', 6),\n",
       " (u'Kids Activities', 6),\n",
       " (u'Bookstores', 6),\n",
       " (u'Austrian', 6),\n",
       " (u'Personal Chefs', 6),\n",
       " (u'Beverage Store', 6),\n",
       " (u'Ethical Grocery', 5),\n",
       " (u'Hobby Shops', 5),\n",
       " (u'Couriers & Delivery Services', 5),\n",
       " (u'Tiki Bars', 5),\n",
       " (u'Arts & Crafts', 5),\n",
       " (u'Gift Shops', 5),\n",
       " (u'Hair Salons', 5),\n",
       " (u'Real Estate', 5),\n",
       " (u'Champagne Bars', 5),\n",
       " (u'Day Spas', 5),\n",
       " (u'Adult Entertainment', 5),\n",
       " (u'Swimming Pools', 5),\n",
       " (u'Curry Sausage', 4),\n",
       " (u'Candy Stores', 4),\n",
       " (u'Community Service/Non-Profit', 4),\n",
       " (u'Playgrounds', 4),\n",
       " (u'Shopping Centers', 4),\n",
       " (u'Supper Clubs', 4),\n",
       " (u'Appliances', 4),\n",
       " (u'Australian', 4),\n",
       " (u'Wine Tasting Room', 4),\n",
       " (u'Laser Tag', 4),\n",
       " (u'Pub Food', 4),\n",
       " (u'Amusement Parks', 4),\n",
       " (u'Department Stores', 4),\n",
       " (u'Syrian', 4),\n",
       " (u'Ethnic Grocery', 4),\n",
       " (u'Public Services & Government', 4),\n",
       " (u'Sugar Shacks', 4),\n",
       " (u'Kitchen & Bath', 4),\n",
       " (u'Florists', 4),\n",
       " (u'Drugstores', 3),\n",
       " (u'Herbs & Spices', 3),\n",
       " (u'Antiques', 3),\n",
       " (u'Nutritionists', 3),\n",
       " (u'Tuscan', 3),\n",
       " (u'Comedy Clubs', 3),\n",
       " (u'Museums', 3),\n",
       " (u'Musicians', 3),\n",
       " (u'Professional Services', 3),\n",
       " (u'Cooking Classes', 3),\n",
       " (u'Bartenders', 3),\n",
       " (u'Trinidadian', 3),\n",
       " (u'Honduran', 3),\n",
       " (u'Haitian', 3),\n",
       " (u'Sporting Goods', 3),\n",
       " (u'Iberian', 3),\n",
       " (u'Pets', 3),\n",
       " (u'Dry Cleaning & Laundry', 2),\n",
       " (u'Vitamins & Supplements', 2),\n",
       " (u'Interior Design', 2),\n",
       " (u'Animal Shelters', 2),\n",
       " (u'Home Decor', 2),\n",
       " (u'Escape Games', 2),\n",
       " (u'Souvenir Shops', 2),\n",
       " (u'Flea Markets', 2),\n",
       " (u'Pita', 2),\n",
       " (u'Screen Printing', 2),\n",
       " (u'Tabletop Games', 2),\n",
       " (u'Nicaraguan', 2),\n",
       " (u'Fitness & Instruction', 2),\n",
       " (u'Japanese Curry', 2),\n",
       " (u'Weight Loss Centers', 2),\n",
       " (u'Distilleries', 2),\n",
       " (u'Recreation Centers', 2),\n",
       " (u'Printing Services', 2),\n",
       " (u'Shared Office Spaces', 2),\n",
       " (u'Colleges & Universities', 2),\n",
       " (u'Themed Cafes', 2),\n",
       " (u'Uzbek', 2),\n",
       " (u'Tours', 2),\n",
       " (u'Leisure Centers', 2),\n",
       " (u'Towing', 2),\n",
       " (u'Wholesale Stores', 2),\n",
       " (u'Hotel bar', 2),\n",
       " (u'Beer Hall', 2),\n",
       " (u'Rock Climbing', 2),\n",
       " (u'Czech', 2),\n",
       " (u'Olive Oil', 2),\n",
       " (u'Car Dealers', 2),\n",
       " (u'Truck Rental', 1),\n",
       " (u'Life Coach', 1),\n",
       " (u'Pet Adoption', 1),\n",
       " (u'Adult Education', 1),\n",
       " (u'Knife Sharpening', 1),\n",
       " (u'DJs', 1),\n",
       " (u'Mountain Biking', 1),\n",
       " (u'Ski Resorts', 1),\n",
       " (u'Travel Services', 1),\n",
       " (u'Pool & Billiards', 1),\n",
       " (u'Zoos', 1),\n",
       " (u'Mauritius', 1),\n",
       " (u'Bikes', 1),\n",
       " (u'Yoga', 1),\n",
       " (u'Milkshake Bars', 1),\n",
       " (u'Building Supplies', 1),\n",
       " (u'Used Bookstore', 1),\n",
       " (u'Climbing', 1),\n",
       " (u'Currency Exchange', 1),\n",
       " (u'Video Game Stores', 1),\n",
       " (u'Hair Removal', 1),\n",
       " (u'Web Design', 1),\n",
       " (u'Discount Store', 1),\n",
       " (u'Tempura', 1),\n",
       " (u'Comic Books', 1),\n",
       " (u'Kombucha', 1),\n",
       " (u'Chiropractors', 1),\n",
       " (u\"Men's Clothing\", 1),\n",
       " (u'Mortgage Brokers', 1),\n",
       " (u'Guest Houses', 1),\n",
       " (u'Car Wash', 1),\n",
       " (u'CSA', 1),\n",
       " (u'Appliances & Repair', 1),\n",
       " (u'Flatbread', 1),\n",
       " (u'Keys & Locksmiths', 1),\n",
       " (u'Trainers', 1),\n",
       " (u'Coffee & Tea Supplies', 1),\n",
       " (u'Nurseries & Gardening', 1),\n",
       " (u'Conveyor Belt Sushi', 1),\n",
       " (u'Club Crawl', 1),\n",
       " (u'Plumbing', 1),\n",
       " (u'Hong Kong Style Cafe', 1),\n",
       " (u'Beach Bars', 1),\n",
       " (u'Czech/Slovakian', 1),\n",
       " (u'Reunion', 1),\n",
       " (u'Furniture Stores', 1),\n",
       " (u'Advertising', 1),\n",
       " (u'Special Education', 1),\n",
       " (u'Rotisserie Chicken', 1),\n",
       " (u'Slovakian', 1),\n",
       " (u'Sicilian', 1),\n",
       " (u'Game Meat', 1),\n",
       " (u'Medical Centers', 1),\n",
       " (u'Airports', 1),\n",
       " (u'Bar Crawl', 1),\n",
       " (u'Farms', 1),\n",
       " (u'Shaved Snow', 1),\n",
       " (u'Popcorn Shops', 1),\n",
       " (u'Yelp Events', 1),\n",
       " (u'Doctors', 1),\n",
       " (u'Strip Clubs', 1),\n",
       " (u'Post Offices', 1),\n",
       " (u'Hostels', 1),\n",
       " (u'Stadiums & Arenas', 1),\n",
       " (u'Wedding Chapels', 1),\n",
       " (u'Botanical Gardens', 1),\n",
       " (u'Libraries', 1),\n",
       " (u'Water Stores', 1),\n",
       " (u'Tasting Classes', 1),\n",
       " (u'Friterie', 1),\n",
       " (u'Auto Repair', 1),\n",
       " (u'Country Clubs', 1),\n",
       " (u'Baby Gear & Furniture', 1),\n",
       " (u'Party Supplies', 1),\n",
       " (u'Toy Stores', 1),\n",
       " (u'Beaches', 1),\n",
       " (u'Pharmacy', 1),\n",
       " (u'Sports Wear', 1),\n",
       " (u'Hainan', 1),\n",
       " (u'Dentists', 1),\n",
       " (u'Bike Rentals', 1),\n",
       " (u'Eastern European', 1),\n",
       " (u\"Women's Clothing\", 1),\n",
       " (u'Pop-up Shops', 1),\n",
       " (u'Virtual Reality Centers', 1),\n",
       " (u'Pet Services', 1),\n",
       " (u'Check Cashing/Pay-day Loans', 1),\n",
       " (u'Security Systems', 1),\n",
       " (u'Cultural Center', 1),\n",
       " (u'Mini Golf', 1),\n",
       " (u'Cheese Tasting Classes', 1),\n",
       " (u'Religious Organizations', 1),\n",
       " (u'Udon', 1),\n",
       " (u'Party Equipment Rentals', 1),\n",
       " (u'Cannabis Clinics', 1),\n",
       " (u'Real Estate Agents', 1),\n",
       " (u'Horseback Riding', 1),\n",
       " (u'Team Building Activities', 1),\n",
       " (u'Videos & Video Game Rental', 1),\n",
       " (u'Drive-Thru Bars', 1),\n",
       " (u'Guamanian', 1),\n",
       " (u'Opera & Ballet', 1),\n",
       " (u'Parks', 1),\n",
       " (u'Bike Repair/Maintenance', 1),\n",
       " (u'Cideries', 1),\n",
       " (u'Sports Clubs', 1),\n",
       " (u'Financial Services', 1),\n",
       " (u'Pop-Up Restaurants', 1),\n",
       " (u'Ticket Sales', 1),\n",
       " (u'Tonkatsu', 1),\n",
       " (u'Cabaret', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "import operator\n",
    "genre_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_count:\n",
    "            genre_count[g] = 1\n",
    "        else:\n",
    "            genre_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genre = ['American (New)', 'Chinese', 'Japanese', 'Italian']\n",
    "\n",
    "# get the key_genre->item_list dict\n",
    "key_genre_item = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_item[k] = list()\n",
    "for item in item_genre_dict:\n",
    "    for g in item_genre_dict[item]:\n",
    "        if g in key_genre:\n",
    "            key_genre_item[g].append(item)\n",
    "            \n",
    "# collect all the items with key genres\n",
    "key_item = list()\n",
    "for genre in key_genre_item:\n",
    "    key_item = key_item + key_genre_item[genre]\n",
    "key_item_set = set(key_item)\n",
    "\n",
    "# remove the non-key genre items in rdf\n",
    "item_set = set(item_list)\n",
    "nonkey_item_set = item_set - key_item_set\n",
    "for item in nonkey_item_set:\n",
    "    rdf.drop(rdf.index[rdf['item_id'] == item], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "rdf_copy = copy.copy(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = copy.copy(rdf_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CxDOIDnH8gp9KXzpBHJYXw    515\n",
       "cMEtAiW60I5wE_vLfTxoJQ    388\n",
       "bLbSNkLggFnqwNNzzq-Ijw    380\n",
       "d_TBs6J3twMy9GChqUEXkg    366\n",
       "PKEzKWv_FktMm2mGPjwd0Q    284\n",
       "U4INQZOPSUaj8hMjLlZ3KA    269\n",
       "DK57YibC5ShBmqQl97CKog    225\n",
       "C2C0GPKvzWWnP57Os9eQ0w    224\n",
       "kjeX2RXvW7RhBbD2QLd5jA    222\n",
       "UYcmGbelzRa0Q6JqzLoguw    221\n",
       "ELcQDlf69kb-ihJfxZyL0A    207\n",
       "S9Jw00eZHVj5_0sOM_C5Rg    205\n",
       "iDlkZO2iILS8Jwfdy7DP9A    204\n",
       "V-BbqKqO8anwplGRx9Q5aQ    201\n",
       "1kNsEAhGU8d8xugMuXJGFA    199\n",
       "2e5V6M4GNufEnbGJpVdCjw    197\n",
       "tH0uKD-vNwMoEc3Xk3Cbdg    194\n",
       "EiP1OFgs-XGcKZux0OKWIA    192\n",
       "dIIKEfOgo0KqUfGQvGikPg    186\n",
       "JaqcCU3nxReTW2cBLHounA    180\n",
       "8DEyKVyplnOcSKx39vatbg    178\n",
       "N3oNEwh0qgPqPP3Em6wJXw    176\n",
       "QJI9OSEn6ujRCtrX06vs1w    171\n",
       "n86B7IkbU20AkxlFX_5aew    164\n",
       "RBZ_kMjowV0t6_nv2UKaDQ    162\n",
       "M9rRM6Eo5YbKLKMG5QiIPA    161\n",
       "pwQ8E-hbDUJe3qtKt_IBBg    160\n",
       "qewG3X2O4X6JKskxyyqFwQ    154\n",
       "oeAhRa8yFa9jtrhaHnOyxQ    145\n",
       "SCo1UBoeN3bhRMkSYuiX1A    145\n",
       "                         ... \n",
       "ntuYgYgQEMj2-skkch2qQw     13\n",
       "9eRRQL3JwekCLFPY25tO2A     13\n",
       "wL-eQ6ZPYj-kUOh2uPavTw     13\n",
       "oK1v-yP9ygKWg6M19wWYIQ     13\n",
       "Lti-z6hPA9gmBmhwkKMwvQ     13\n",
       "rwxIAhvgoYQZr6VNz1lvhA     13\n",
       "7fsw7xwm-eamdoQgx4r3_Q     13\n",
       "QWPOtEzqFpZJHJCAZpARww     13\n",
       "42P_hSlGg0Lgj6wl9-eDjw     13\n",
       "XopP_70iyfC3iCPAY-sz4Q     13\n",
       "aZtJzH3fRIRzrGnQRIVaRg     13\n",
       "5Bmt9x2gWpOYuj5NXceftg     13\n",
       "nW6CQYofA5tVnHTMlIxoHA     13\n",
       "VsCfXwyXAlot_txADiLv6g     13\n",
       "9-BuUslaWcCL6yLRTagYfw     13\n",
       "nUN2FOWj4G3ZmyCeDkq-FA     13\n",
       "lhPuskGXTRSjCwKOOOYeoA     13\n",
       "NHwqfU8b_8cf1H05FDt9Eg     13\n",
       "6zsuSuLEwhUNHEWSDJqt-Q     12\n",
       "sswLzPBbKIIVwlbJRS2NPA     12\n",
       "TLoT03bwXNTNj3m8egcjXg     12\n",
       "vuH41CWzOYlwKmMmZnjV7g     12\n",
       "BytRWk8X1OelSgwwfXd8Aw     12\n",
       "ERIkO4lCb4QQCT3kcqoabw     12\n",
       "K0Ha-V9ROBlTab4moVEzGQ     12\n",
       "_ZMaPWnNVuwDBfufMllS8g     12\n",
       "8U9bQ6ctbM6HCB9hqTCUTw     12\n",
       "A2l6pDAwA5SkfuOd7E_npw     12\n",
       "xXwkBx46TvgQh5FoxSKoAw     12\n",
       "Nl2mdXCEaIq7WPiaugHdlw     12\n",
       "Name: user_id, Length: 8263, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteratively remove items and users with less than 5 reviews\n",
    "\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['user_freq'] <= 12], inplace=True)\n",
    "rdf['item_freq'] = rdf.groupby('item_id')['item_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['item_freq'] <= 12], inplace=True)\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 4420\n",
      "user num = 8263\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_id_dict:\n",
    "        user_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_id_dict:\n",
    "        item_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.00579684391468\n"
     ]
    }
   ],
   "source": [
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/8263\n"
     ]
    }
   ],
   "source": [
    "# get the df of train, vali, and test set\n",
    "rdf.reset_index(inplace=True, drop=True)\n",
    "train_df = rdf.copy()\n",
    "vali_df = rdf.copy()\n",
    "test_df = rdf.copy()\n",
    "\n",
    "train_ratio = 0.6\n",
    "vali_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_all = len(rdf)\n",
    "vali_idx = []\n",
    "test_idx = []\n",
    "\n",
    "test_vali_idx = []\n",
    "i = 0\n",
    "num_user = len(user_list)\n",
    "for u in user_list:\n",
    "    u_idx = train_df.index[train_df['user_id'] == u]\n",
    "    idx_len = len(u_idx)\n",
    "    test_len = int(idx_len * (test_ratio + vali_ratio))\n",
    "    if test_len == 0:\n",
    "        test_len = 1\n",
    "    tmp = np.random.choice(u_idx, size=test_len, replace=False)\n",
    "    test_vali_idx += tmp.tolist()\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print(str(i) + '/' + str(num_user))\n",
    "\n",
    "# tmp = (np.random.choice(range(num_all), size=(test_len+vali_len), replace=False)).tolist()\n",
    "test_len = int(len(test_vali_idx) * test_ratio / (test_ratio + vali_ratio))\n",
    "vali_len = int(len(test_vali_idx) - test_len)\n",
    "test_idx = (np.random.choice(test_vali_idx, size=test_len, replace=False)).tolist()\n",
    "vali_idx = (np.random.choice(test_vali_idx, size=vali_len, replace=False)).tolist()\n",
    "\n",
    "test_set = set(test_idx)\n",
    "vali_set = set(vali_idx)\n",
    "train_set = set(range(num_all)) - test_set - vali_set\n",
    "train_idx = list(train_set)\n",
    "train_df.drop((test_idx + vali_idx), axis=0, inplace=True)\n",
    "test_df.drop((train_idx + vali_idx), axis=0, inplace=True)\n",
    "vali_df.drop((train_idx + test_idx), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.drop(columns=['rating'], inplace=True)\n",
    "train_df.drop(columns=['rating'], inplace=True)\n",
    "test_df.drop(columns=['rating'], inplace=True)\n",
    "vali_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix of train, vali and test set\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "train = np.zeros((len(user_list), len(item_list)))\n",
    "test = np.zeros((len(user_list), len(item_list)))\n",
    "vali = np.zeros((len(user_list), len(item_list)))\n",
    "for r in range(len(train_df)):\n",
    "    train[user_id_dict[train_df.at[r, 'user_id']], item_id_dict[train_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(test_df)):\n",
    "    test[user_id_dict[test_df.at[r, 'user_id']], item_id_dict[test_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(vali_df)):\n",
    "    vali[user_id_dict[vali_df.at[r, 'user_id']], item_id_dict[vali_df.at[r, 'item_id']]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user int id-> str id list, and the same for item \n",
    "item_list = item_id_dict.keys()\n",
    "item_idd_list = list()\n",
    "for i in range(len(item_list)):\n",
    "    item_idd_list.append('')\n",
    "for item in item_id_dict:\n",
    "    item_idd_list[item_id_dict[item]] = item\n",
    "\n",
    "user_list = user_id_dict.keys()\n",
    "user_idd_list = list()\n",
    "for i in range(len(user_list)):\n",
    "    user_idd_list.append('')\n",
    "for user in user_id_dict:\n",
    "    user_idd_list[user_id_dict[user]] = user\n",
    "    \n",
    "# get the item int id->genres list\n",
    "item_idd_genre_list = list()\n",
    "for i in range(len(item_idd_list)):\n",
    "    item_idd_genre_list.append(item_genre_dict[item_idd_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('user_freq', axis=1, inplace=True)\n",
    "train_df.drop('item_freq', axis=1, inplace=True)\n",
    "vali_df.drop('user_freq', axis=1, inplace=True)\n",
    "vali_df.drop('item_freq', axis=1, inplace=True)\n",
    "test_df.drop('user_freq', axis=1, inplace=True)\n",
    "test_df.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df for rdf, train, vali, test with int id for user and item\n",
    "import copy\n",
    "rating_df = copy.copy(rdf)\n",
    "for i in range(len(rdf)):\n",
    "    rating_df.at[i, 'user_id'] = user_id_dict[rating_df.at[i, 'user_id']]\n",
    "    rating_df.at[i, 'item_id'] = item_id_dict[rating_df.at[i, 'item_id']]\n",
    "\n",
    "training_df = copy.copy(train_df)\n",
    "for i in range(len(training_df)):\n",
    "    training_df.at[i, 'user_id'] = user_id_dict[training_df.at[i, 'user_id']]\n",
    "    training_df.at[i, 'item_id'] = item_id_dict[training_df.at[i, 'item_id']]\n",
    "\n",
    "valiing_df = copy.copy(vali_df)\n",
    "for i in range(len(valiing_df)):\n",
    "    valiing_df.at[i, 'user_id'] = user_id_dict[valiing_df.at[i, 'user_id']]\n",
    "    valiing_df.at[i, 'item_id'] = item_id_dict[valiing_df.at[i, 'item_id']]\n",
    "\n",
    "testing_df = copy.copy(test_df)\n",
    "for i in range(len(testing_df)):\n",
    "    testing_df.at[i, 'user_id'] = user_id_dict[testing_df.at[i, 'user_id']]\n",
    "    testing_df.at[i, 'item_id'] = item_id_dict[testing_df.at[i, 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the rating list for each key genre, get the genre->ratings dict\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "key_genre_rating = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_rating[k] = 0.0\n",
    "for r in range(len(rdf)):\n",
    "    item = rdf.at[r, 'item_id']\n",
    "    gl = item_genre_dict[item]\n",
    "    for k in key_genre:\n",
    "        if k in gl:\n",
    "            key_genre_rating[k] += 1.0\n",
    "\n",
    "# get the item int id->genres list\n",
    "genre_item_vector = dict()\n",
    "for k in key_genre:\n",
    "    genre_item_vector[k] = np.zeros((1, len(item_list)))\n",
    "for i in range(len(item_idd_genre_list)):\n",
    "    genre_list = item_idd_genre_list[i]\n",
    "    for g in genre_list:\n",
    "        if g in key_genre:\n",
    "            genre_item_vector[g][0, i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"item_genre_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_genre_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"genre_item_vector.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_item_vector, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(\"rdf.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(rdf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rating_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rating_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"training_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"valiing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valiing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"testing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(testing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_genre_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_genre_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre_rating.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre_rating, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"train.mat\", \"wb\") as f:\n",
    "    np.save(f, train)\n",
    "with open(\"test.mat\", \"wb\") as f:\n",
    "    np.save(f, test)\n",
    "with open(\"vali.mat\", \"wb\") as f:\n",
    "    np.save(f, vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'American (New)', 1610),\n",
       " (u'Italian', 1055),\n",
       " (u'Chinese', 984),\n",
       " (u'Japanese', 946)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "# item_list = pickle.load(open('./rdf.pkl'))['item_id'].unique()\n",
    "# item_genre_dict = pickle.load(open('./item_genre_dict.pkl'))\n",
    "# key_genre = pickle.load(open('./key_genre.pkl'))\n",
    "\n",
    "genre_count = dict()\n",
    "for i in item_list:\n",
    "    gl = item_genre_dict[i]\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            if not g in genre_count:\n",
    "                genre_count[g] = 1\n",
    "            else:\n",
    "                genre_count[g] += 1\n",
    "\n",
    "with open(\"genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_count, f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "genre_count_sorted = sorted(genre_count.items(), key=itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy as copy\n",
    "\n",
    "item_idd_genre_list = np.array(item_idd_genre_list)\n",
    "\n",
    "\n",
    "mask = 1.0 * (train > 0)\n",
    "user_genre_count = list()\n",
    "for u in range(train.shape[0]):\n",
    "    temp_genre_count = copy.copy(genre_count)\n",
    "    mask_u = mask[u, :]\n",
    "    gll = item_idd_genre_list[mask_u == 1.0]\n",
    "    for gl in gll:\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                temp_genre_count[g] -= 1\n",
    "    user_genre_count.append(temp_genre_count)\n",
    "with open(\"user_genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_genre_count, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_like = dict()\n",
    "for k in key_genre:\n",
    "    genre_avg_like[k] = key_genre_rating[k] * 1.0 / genre_count[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American (New)', 56.844099378881985),\n",
       " ('Japanese', 48.10570824524313),\n",
       " ('Italian', 44.0132701421801),\n",
       " ('Chinese', 37.326219512195124)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_avg_like_sorted = sorted(genre_avg_like.items(), key=itemgetter(1), reverse=True)\n",
    "genre_avg_like_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
